{"cells":[{"cell_type":"markdown","id":"32b1dc5e","metadata":{"id":"32b1dc5e"},"source":["### This file extracts audio files from directories.\n","1. The audio files are stored in different folders with their respective class name.\n","2. The functions will extract melspectrogram and mfcc from each audio files\n","3. For alignment, the audio files are sliced according the `seg size`(in this sample,seg=30).\n","4. If the segmentation has sample size less than `seg size` but more than half of it, it will be padded with 0s. Else erased."]},{"cell_type":"code","execution_count":1,"id":"8bd8ac4a","metadata":{"executionInfo":{"elapsed":346,"status":"ok","timestamp":1656390435210,"user":{"displayName":"XiangRui Liu","userId":"12428559882116548779"},"user_tz":-480},"id":"8bd8ac4a"},"outputs":[],"source":["import os\n","import numpy as np\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":2,"id":"5c3ea234","metadata":{},"outputs":[{"data":{"text/plain":["'1.23.3'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["np.__version__"]},{"cell_type":"code","execution_count":3,"id":"6344af79","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1656390438195,"user":{"displayName":"XiangRui Liu","userId":"12428559882116548779"},"user_tz":-480},"id":"6344af79"},"outputs":[],"source":["root_dir = \"/home/assa8945/MMC/Dataset/test_data/MOBY\"\n","# root_dir = \"D:\\A\\Marine Mammal Detection\\datasets\\AAAI23\\\\3classes\\\\audio\"\n","seg = 60\n","sample_rate = 48000\n","# save_dir =  \"D:\\A\\Marine Mammal Detection\\datasets\\\\\"+\"100khz_seg_\"+str(seg)+\"_mean_padded\"\n","save_dir = \"/home/assa8945/MMC/Dataset/features/watkins_full/testsets\"\n","if os.path.exists(save_dir):\n","    pass\n","else:\n","    os.mkdir(save_dir)"]},{"cell_type":"code","execution_count":4,"id":"46a7e23d","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1656390438196,"user":{"displayName":"XiangRui Liu","userId":"12428559882116548779"},"user_tz":-480},"id":"46a7e23d"},"outputs":[],"source":["def slicing_and_padding_single_data(data,seg=30):\n","    \"\"\"_summary_\n","\n","    Args:\n","        data_list (_type_): A data list that contains 2D arrays data.\n","        seg (int, optional): The length of each sliced data. Defaults to 30.\n","    \"\"\"\n","    new_data_list = []\n","\n","    data_length = data.shape[0] # The length of original 2D data sample.\n","    seg_counter = 0\n","    while data_length > 0:\n","        if data_length>=seg:\n","\n","            new_data_list.append(data[seg_counter:seg_counter + seg,:])\n","            data_length -= seg\n","            seg_counter += seg\n","\n","        elif data_length >= seg/2:  #when the left data_length is less than seg size but large than half of seg size, pad it up to seg size\n","            \n","           # pad the sample mean\n","            average = data.mean(axis=0)\n","            missing_length = seg-data_length\n","            averages_pads = np.tile(average,(missing_length,1))\n","            padded_data = np.vstack((data[seg_counter:,:],averages_pads))\n","            # print(padded_data.shape)\n","\n","            #pad 0s \n","            # pad = np.zeros((seg-data_length,data.shape[1]))\n","            # padded_data = np.vstack((data[seg_counter:,:],pad))\n","\n","\n","            #pad last frame\n","            # last_frame = data[-1,:]\n","            # missing_length = seg-data_length\n","            # pad = np.tile(last_frame,(missing_length,1))\n","            # padded_data = np.vstack((data[seg_counter:,:],pad))\n","\n","\n","\n","            # print(padded_data.shape)\n","            new_data_list.append(padded_data)\n","            break\n","        else: #when the row number is less than half of the segment , pass the rows.\n","            break\n","    return new_data_list\n"]},{"cell_type":"code","execution_count":5,"id":"7a3bed76","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1082467,"status":"ok","timestamp":1656391520657,"user":{"displayName":"XiangRui Liu","userId":"12428559882116548779"},"user_tz":-480},"id":"7a3bed76","outputId":"b14c76b8-fb83-4bfd-8879-00407ccf4a9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Fin Whale', 'Bowhead Whale']\n","going through folder /home/assa8945/MMC/Dataset/test_data/MOBY/Fin Whale\n","processing file 93-001-1723.ch11.wav\n","processing file 93-002-1114.ch07.wav\n","processing file 93-055-0536.ch10.wav\n","processing file 93-001-1450.ch11.wav\n","processing file 93-042-1013.ch06.wav\n","processing file 93-050-1654.ch10.wav\n","processing file 93-002-0244.ch11.wav\n","processing file 93-002-0830.ch11.wav\n","processing file 93-040-1235.ch10.wav\n","processing file 93-050-1234.ch10.wav\n","processing file 93-001-1217.ch04.wav\n","processing file 93-002-0551.ch11.wav\n","processing file 93-042-0015.ch10.wav\n","processing file 93-041-0244.ch16.wav\n","processing file 93-050-1942.ch10.wav\n","There are 117955 sliced and padded data samples under \n","/home/assa8945/MMC/Dataset/test_data/MOBY/Fin Whale\n","\n","going through folder /home/assa8945/MMC/Dataset/test_data/MOBY/Bowhead Whale\n","processing file B88042519.1936.wav\n","processing file B88041902.0347.wav\n","processing file B88042107.0509b.wav\n","processing file B88041903.0424.wav\n","processing file B88041903.0408b.wav\n","processing file B88042020.1629.wav\n","processing file B88042614.1112.wav\n","processing file B88042024.1955a.wav\n","processing file B88042518.1818.wav\n","processing file B88042519.1941.wav\n","processing file B88042011.0932.wav\n","processing file B88042104.0240b.wav\n","processing file B88042521.2111.wav\n","processing file B88042007.0558.wav\n","processing file B88042519.1926.wav\n","processing file B88042615.1229a.wav\n","processing file B88042521.2116.wav\n","processing file B88042521.2118.wav\n","processing file B88042024.1948b.wav\n","processing file B88042522.2146.wav\n","processing file B88042020.1636b.wav\n","processing file B88042520.1958b.wav\n","processing file B88041902.0312.wav\n","processing file B88042003.0301.wav\n","processing file B88042104.0241.wav\n","processing file B88042104.0146.wav\n","processing file B88042109.0715.wav\n","processing file B88041902.0349.wav\n","processing file B88042020.1626a.wav\n","processing file B88042106.0450b.wav\n","processing file B88042519.1939.wav\n","processing file B88042520.2037.wav\n","processing file B88042103.0218.wav\n","processing file B88042109.0713b.wav\n","processing file B88042606.0520.wav\n","processing file B88042003.0253.wav\n","processing file B88042104.0236.wav\n","processing file B88042109.0714b.wav\n","processing file B88042109.0712b.wav\n","processing file B88042024.1936b.wav\n","processing file B88042107.0519.wav\n","processing file B88042107.0526.wav\n","processing file B88042518.1834b.wav\n","processing file B88041902.0313.wav\n","processing file B88042518.1836b.wav\n","processing file B88042107.0511.wav\n","processing file B88042104.0231.wav\n","processing file B88042519.1935.wav\n","processing file B88042521.2117.wav\n","processing file B88042518.1832.wav\n","processing file B88042007.0548.wav\n","processing file B88042519.1922.wav\n","processing file B88042521.2056.wav\n","processing file B88042104.0237.wav\n","processing file B88041902.0318.wav\n","processing file B88042005.0406.wav\n","processing file B88042024.1938b.wav\n","processing file B88042522.2136.wav\n","processing file B88042024.1940b.wav\n","processing file B88042020.1634.wav\n","processing file B88041902.0322.wav\n","processing file B88041902.0328b.wav\n","processing file B88042104.0249.wav\n","processing file B88042003.0259.wav\n","processing file B88042005.0407b.wav\n","processing file B88041902.0354.wav\n","processing file B88042107.0452.wav\n","processing file B88042004.0323a.wav\n","processing file B88042522.2140.wav\n","processing file B88042104.0230.wav\n","processing file B88042104.0248.wav\n","processing file B88042109.0702b.wav\n","processing file B88042519.1937.wav\n","processing file B88041902.0325a.wav\n","processing file B88042004.0319.wav\n","processing file B88042106.0449.wav\n","processing file B88041902.0344.wav\n","processing file B88042002.0144.wav\n","processing file B88042615.1229b.wav\n","processing file B88041902.0317a.wav\n","processing file B88042522.2133.wav\n","processing file B88042521.2050.wav\n","processing file B88042519.1927.wav\n","processing file B88042613.1050.wav\n","processing file B88041903.0438b.wav\n","processing file B88042107.0530.wav\n","processing file B88042104.0240a.wav\n","processing file B88042518.1816.wav\n","processing file B88042020.1624a.wav\n","processing file B88042606.0510.wav\n","processing file B88042521.2040.wav\n","processing file B88042521.2122.wav\n","processing file B88042614.1110.wav\n","processing file B88042104.0233.wav\n","processing file B88042107.0516b.wav\n","processing file B88041902.0315.wav\n","processing file B88041904A.0454b.wav\n","processing file B88042522.2139.wav\n","processing file B88042107.0533.wav\n","processing file B88041902.0346.wav\n","processing file B88041902.0358.wav\n","processing file B88042614.1109.wav\n","processing file B88042521.2124.wav\n","processing file B88041903.0419.wav\n","processing file B88042104.0245.wav\n","processing file B88041902.0321.wav\n","processing file B88042010.0839.wav\n","processing file B88041902.0333b.wav\n","processing file B88042521.2103.wav\n","processing file B88042005.0359b.wav\n","processing file B88042024.1953.wav\n","processing file B88042519.1912.wav\n","processing file B88041903.0408a.wav\n","processing file B88042107.0456.wav\n","processing file B88042521.2113.wav\n","processing file B88042613.1047b.wav\n","processing file B88042519.1914.wav\n","processing file B88042107.0458.wav\n","processing file B88042003.0307.wav\n","processing file B88042104.0229.wav\n","processing file B88042107.0503.wav\n","processing file B88042007.0546b.wav\n","processing file B88042107.0528b.wav\n","processing file B88042107.0505.wav\n","processing file B88042016.1326.wav\n","processing file B88042605.0433.wav\n","processing file B88042020.1628a.wav\n","processing file B88042519.1945.wav\n","processing file B88042521.2043.wav\n","processing file B88042520.2000.wav\n","There are 6203 sliced and padded data samples under \n","/home/assa8945/MMC/Dataset/test_data/MOBY/Bowhead Whale\n","\n"]}],"source":["def batch_feature_extraction(dir,sample_rate,seg=seg,):\n","    \"\"\"_summary_\n","\n","    Args:\n","        dir (_type_): Root folder directory that contains differents classes' folders.\n","\n","    Returns:\n","        _type_: spectrogram list, mfcc list\n","    \"\"\"\n"," \n","    # Save the folders' directories to a list according to the classes.\n","    \n","    folder_list = []\n","    class_list = []\n","    for root,folders,files in os.walk(dir):\n","        for folder in folders:\n","\n","            folder_list.append(os.path.join(root,folder))\n","            class_list.append(folder)\n","    # print(folder_list)\n","\n","    print(class_list)\n","    for folder_dir in folder_list:\n","        \n","        specs = []\n","        mfccs = []\n","        print('going through folder',folder_dir)\n","        for file in os.listdir(folder_dir):\n","            \n","            if file.endswith(\".csv\"):\n","                continue\n","\n","            audio_name = file\n","            print('processing file',audio_name)\n","            audio_dir = os.path.join(folder_dir,audio_name)\n","            # print(audio_dir)\n","\n","            y, sr = librosa.load(audio_dir,sr=sample_rate) #default sample rate 22050\n","            if len(y)<2048:\n","                print('The length of audio is less than 2048 samples ',audio_dir)\n","                continue\n","            \n","            # Calculate spectrogram\n","            spec = librosa.feature.melspectrogram(y=y,sr=sr,n_mels=240)\n","            spec = librosa.power_to_db(spec)\n","            spec = spec.T\n","            # print(spec.shape)\n","            modified_spec = slicing_and_padding_single_data(spec,seg=seg)\n","            specs.extend(modified_spec)           \n","            \n","            # Calculate mfcc\n","            mfcc = librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40)\n","            mfcc = mfcc.T\n","            # print(mfcc.shape)\n","            modified_mfcc = slicing_and_padding_single_data(mfcc,seg=seg)\n","            \n","            mfccs.extend(modified_mfcc)\n","\n","#-------------------------------------------------------------------------------------------\n","# Assert that all the data has correct shape\n","        assert len(specs)==len(mfccs),AssertionError\n","        print('There are {} sliced and padded data samples under \\n{}\\n'.format(len(specs),folder_dir))\n","        \n","        for i in specs:\n","            assert i.shape[0]==seg,print(i.shape)\n","        for j in mfccs:\n","            assert j.shape[0]==seg,print(j.shape)\n","#-------------------------------------------------------------------------------------------\n","\n","\n","#-------------------------------------------------------------------------------------------\n","# Save the data into csv files to respective directories\n","        specs = np.array(specs)\n","        # print(specs.shape)\n","        mfccs = np.array(mfccs)\n","        # print(mfccs.shape)\n","        reshaped_specs = specs.reshape(specs.shape[0],-1)\n","        reshaped_mfccs = mfccs.reshape(mfccs.shape[0],-1)\n","\n","        np.savetxt(os.path.join(folder_dir,'mfccs.csv'), reshaped_mfccs, delimiter=\",\")\n","        np.savetxt(os.path.join(folder_dir,'specs.csv'), reshaped_specs, delimiter=\",\")\n","\n","\n","batch_feature_extraction(root_dir,sample_rate=sample_rate,seg=seg)"]},{"cell_type":"code","execution_count":6,"id":"7a08cef9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142850,"status":"ok","timestamp":1656392823219,"user":{"displayName":"XiangRui Liu","userId":"12428559882116548779"},"user_tz":-480},"id":"7a08cef9","outputId":"e0c3d792-5c58-4fec-d50a-a6ef1879da3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Fin Whale', 'Fin Whale'), ('Bowhead Whale', 'Bowhead Whale')]\n","\n","The overall mfcc data has shape of  (124158, 60, 40)\n","\n","The overall spectrogram data has shape of  (124158, 60, 240)\n","\n","The labels have shape of  (124158, 1)\n"]}],"source":["def merge_and_labels(root_dir,seg):\n","    folders = os.listdir(root_dir)\n","    labels = []\n","    collected_specs = np.empty((1,seg,240))\n","    collected_mfccs = np.empty((1,seg,40))\n","    collected_y = np.empty((1,1))\n","    for folder in folders:\n","        if folder.endswith('csv'):\n","            continue \n","        folder_dir = os.path.join(root_dir,folder)\n","        \n","        specs = np.loadtxt(os.path.join(folder_dir,\"specs.csv\"), delimiter=\",\")\n","        mfccs = np.loadtxt(os.path.join(folder_dir,\"mfccs.csv\"), delimiter=\",\")\n","        \n","        # Restore data to 3D\n","        specs = specs.reshape(-1,seg,240)\n","        mfccs = mfccs.reshape(-1,seg,40)\n","        y = np.full((specs.shape[0],1),folder)\n","\n","        # Stack them up\n","        collected_specs = np.vstack((collected_specs,specs))\n","        collected_mfccs = np.vstack((collected_mfccs,mfccs))\n","        collected_y = np.vstack((collected_y,y))\n","        \n","        labels.append((folder,folder))\n","\n","    # Remove the empty sample 0 (created for initialization)    \n","    collected_specs = np.delete(collected_specs,0,0)\n","    collected_mfccs = np.delete(collected_mfccs,0,0)\n","    collected_y = np.delete(collected_y,0,0)\n","\n","\n","    print(labels) \n","    \n","    print('\\nThe overall mfcc data has shape of ',collected_mfccs.shape)\n","\n","    print('\\nThe overall spectrogram data has shape of ',collected_specs.shape)\n","    print('\\nThe labels have shape of ',collected_y.shape)\n","\n","    return collected_specs,collected_mfccs,collected_y\n","\n","collected_specs,collected_mfccs,collected_y = merge_and_labels(root_dir,seg)"]},{"cell_type":"code","execution_count":7,"id":"27e6f05a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152073,"status":"ok","timestamp":1656393049635,"user":{"displayName":"XiangRui Liu","userId":"12428559882116548779"},"user_tz":-480},"id":"27e6f05a","outputId":"1839da57-2fc2-4fce-dca3-1608e71ceac7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(124158, 60, 40)\n","saving data to:  /home/assa8945/MMC/Dataset/features/watkins_full/testsets\n","completed\n"]}],"source":["# The 3D arrays are reshaped into 2D arrays so can be save to csv files\n","reshaped_mfccs=collected_mfccs.reshape(collected_mfccs.shape[0],-1)\n","reshaped_specs=collected_specs.reshape(collected_specs.shape[0],-1)\n","print(collected_mfccs.shape)\n","\n","if os.path.exists(save_dir):\n","    pass\n","else:\n","    os.mkdir(save_dir)\n","\n","print(\"saving data to: \",save_dir)\n","\n","np.savez(os.path.join(save_dir,'mfccs.npy.npz'),*collected_mfccs)\n","np.savez(os.path.join(save_dir,'specs.npy.npz'),*collected_specs)\n","np.savez(os.path.join(save_dir,'specs_labeled.npy.npz'),collected_specs,collected_y)\n","# np.savetxt(os.path.join(save_dir,'labels.csv'), collected_y, delimiter=\",\")\n","\n","print('completed')"]},{"cell_type":"code","execution_count":null,"id":"fb3293d1","metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"Dataset_prep(Watkins).ipynb","provenance":[]},"kernelspec":{"display_name":"py39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"ecabaab5aa15e3c70ccdd8c9af1b27eebe11a07043e5733675f5e7e2ee8b9fc1"}}},"nbformat":4,"nbformat_minor":5}
